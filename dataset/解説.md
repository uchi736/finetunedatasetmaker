# データセット作成フォルダ 解説

## 📋 概要

このフォルダは、PDFファイル（統合報告書、技術文書など）からLLMファインチューニング用のデータセットを作成するためのツール群を含んでいます。

主な機能:
- PDFからテキスト・画像の高精度抽出
- 図表の自動解説生成（Google Gemini Vision API利用）
- LLM学習用JSONL形式への変換
- データセットの前処理とフォーマット変換

---

## 📁 ファイル構成

### メインスクリプト

#### `datasetmaker.py`
PDFファイルからデータセットを作成するメインスクリプト

**主な機能:**
- レイアウト保持型の高精度テキスト抽出
- 見出し階層の自動認識
- 表の構造化抽出とMarkdown変換
- 図表のキャプション抽出と画像解説（Gemini Vision API）
- 2段組レイアウトの正確な読み順保持
- JSONL形式でのチャンク化出力

**主要クラス:**
- `LayoutAnalyzer`: PDFレイアウト解析
- `VisionAnalyzer`: 画像の自動解説生成
- `DatasetGenerator`: データセット生成のメインクラス

#### `preprocess_dataset.py`
Dolly-JAデータセットをLlama-3形式にフォーマットするスクリプト

**機能:**
- Dolly-JAデータセットのダウンロードと読み込み
- Llama-3形式（`<|begin_of_text|>`等のトークン）への変換
- 学習用/検証用データの分割（9:1）
- フォーマット済みデータのJSONL出力

**処理の流れ:**
1. `kunishou/databricks-dolly-15k-ja`データセットを読み込み
2. システムプロンプトを含むLlama-3形式に変換
3. `preprocessed_dolly_ja/`フォルダに保存

### ユーティリティスクリプト

#### `clean_jsonl.py`
JSONL形式ファイルのクリーニングツール

#### `jsonl_viewer.py`
JSONL形式ファイルの内容を確認するビューアー

### 設定ファイル

#### `requirements.txt`
必要なPythonパッケージ一覧

```
pymupdf              # PDFパース（PyMuPDF）
pymupdf4llm          # PDF→Markdown変換
python-dotenv        # 環境変数管理
langchain            # テキスト分割
google-generativeai  # Gemini API
Pillow               # 画像処理
transformers         # トークナイザー
torch                # PyTorch
nltk                 # 自然言語処理
```

#### `.env`
API設定ファイル（機密情報を含むため.gitignoreに追加推奨）

```env
GEMINI_API_KEY=your_api_key_here
```

---

## 📂 データファイル

### 入力PDFファイル

| ファイル名 | 内容 | サイズ |
|-----------|------|--------|
| `1.pdf` | ウエルシアホールディングス統合報告書2024 | 19.4MB |
| `h24_report02_ref01.pdf` | 報告書サンプル | 2.4MB |
| `Hada.pdf` | 肌関連文書 | 1.1MB |
| `Wiki.pdf` | Wikipedia抽出文書 | 1.2MB |
| `モデル就業規則.pdf` | 就業規則サンプル | 329KB |

### 出力JSONLファイル

| ファイル名 | 説明 |
|-----------|------|
| `1_preprocessed.jsonl` | 1.pdfの前処理済みデータ（2.4MB） |
| `1_dataset.jsonl` | 1.pdfのデータセット版（2.6MB） |
| `1_preprocessed_en.jsonl` | 英語版サンプル（5KB） |
| `*_preprocessed.jsonl` | その他PDFの前処理済みデータ |

**JSONLフォーマット:**
```json
{
  "id": "1_c1",
  "text": "抽出されたテキスト内容...",
  "meta": {
    "source_file": "1.pdf",
    "chunk_id": 1,
    "section_path": "見出し階層",
    "page_start": 1,
    "page_end": 1,
    "hierarchical_level": 0
  }
}
```

### その他のフォルダ

- `extracted_images/`: PDFから抽出された画像ファイル
- `preprocessed_dolly_ja/`: Dolly-JAの前処理済みデータ
- `myenv/`: Python仮想環境（ローカル環境）

---

## 🚀 使い方

### 1. 環境セットアップ

```bash
# 仮想環境の作成（任意）
python -m venv myenv
myenv\Scripts\activate  # Windows
# source myenv/bin/activate  # macOS/Linux

# パッケージのインストール
pip install -r requirements.txt
```

### 2. API設定

`.env`ファイルを作成し、Google Gemini APIキーを設定:

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

Gemini APIキーの取得: https://ai.google.dev/

### 3. PDFからデータセット作成

```bash
# datasetmaker.pyを実行
python datasetmaker.py
```

スクリプト内でPDFファイルパスを指定して実行すると:
1. PDFからテキスト・画像を抽出
2. 図表をGemini Vision APIで解説
3. `*_dataset.jsonl`として出力

### 4. Dolly-JAデータセットの前処理

```bash
# preprocess_dataset.pyを実行
python preprocess_dataset.py
```

実行すると:
1. Dolly-JAデータセットを自動ダウンロード
2. Llama-3形式に変換
3. `preprocessed_dolly_ja/`フォルダに保存

---

## ⚙️ カスタマイズ

### datasetmaker.pyの主要パラメータ

```python
# チャンクサイズの調整
chunk_size = 1000      # 1チャンクの最大文字数
chunk_overlap = 200    # チャンク間のオーバーラップ

# Vision API設定
vision_model = "gemini-1.5-flash"  # モデル選択
temperature = 0.3                   # 生成の多様性

# レイアウト解析
detect_two_column = True  # 2段組検出の有効化
```

### preprocess_dataset.pyの設定

```python
model_id = "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2"  # モデルID
output_dir = "./preprocessed_dolly_ja"                 # 出力先
test_size = 0.1  # 検証データの割合
```

---

## ⚠️ 注意事項

1. **APIキーの管理**
   - `.env`ファイルは機密情報を含むため、Gitにコミットしないこと
   - `.gitignore`に`.env`を追加推奨

2. **大容量ファイル**
   - PDFファイルやJSONLファイルは大容量になる場合があるため、Git LFSの使用を検討

3. **API利用料金**
   - Gemini Vision APIは無料枠がありますが、大量処理時は料金が発生する可能性あり
   - 料金プラン: https://ai.google.dev/pricing

4. **依存関係**
   - PyTorchはGPU版とCPU版があります。環境に応じてインストール方法を調整してください
   - GPU環境の場合: https://pytorch.org/get-started/locally/

---

## 📊 処理フロー

```
PDF入力
  ↓
[datasetmaker.py]
  ├─ テキスト抽出（PyMuPDF）
  ├─ レイアウト解析
  ├─ 図表抽出
  ├─ Vision API解説生成
  └─ JSONL出力
  ↓
*_dataset.jsonl
  ↓
[LLMファインチューニング]
```

---

## 📝 トラブルシューティング

### `ModuleNotFoundError: No module named 'XXX'`
→ `pip install -r requirements.txt`で依存パッケージを再インストール

### Vision API関連のエラー
→ `.env`ファイルにGEMINI_API_KEYが正しく設定されているか確認

### NLTK関連のエラー
→ スクリプトが初回実行時に自動的に`punkt`データセットをダウンロードします

---

## 📚 参考リンク

- [PyMuPDF Documentation](https://pymupdf.readthedocs.io/)
- [Google Gemini API](https://ai.google.dev/)
- [LangChain Documentation](https://python.langchain.com/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)

---

## 📄 ライセンス

各ツールやライブラリのライセンスに従ってください。
